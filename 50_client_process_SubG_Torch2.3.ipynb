{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2662e38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd8fb061-0f10-4ad9-ab36-1148ee49cdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets.base_dataset import BaseDataset\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils import to_numeric\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7055a76-f724-4806-b51b-6db5fe4f5025",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ADULT(BaseDataset):\n",
    "\n",
    "    def __init__(self, name='ADULT', single_bit_binary=False, device='cpu', random_state=42, name_state=\"CA\"):\n",
    "        super(ADULT, self).__init__(name=name, device=device, random_state=random_state)\n",
    "        print(name_state)\n",
    "        self.features = {\n",
    "            'AGEP': None,\n",
    "            'COW': None,\n",
    "            'SCHL': None,\n",
    "            'MAR': None,\n",
    "            'OCCP': None,\n",
    "            'POBP': None,\n",
    "            'RELP': None,\n",
    "            'WKHP': None,\n",
    "            'SEX': None,\n",
    "            'RAC1P': None,      \n",
    "            'PINCP': ['>50K', '<=50K']\n",
    "        }\n",
    "        \n",
    "        self.single_bit_binary = single_bit_binary\n",
    "        self.label = 'PINCP'\n",
    "\n",
    "        self.train_features = {key: self.features[key] for key in self.features.keys() if key != self.label}\n",
    "\n",
    "        # name_state=\"CA\"\n",
    "        self.train_data_df = pd.read_csv(f'50_clients_data/client_subG_splits/{name_state}.data', delimiter=',', names=list(self.features.keys()), engine='python')\n",
    "        \n",
    "        self.test_data_df = pd.read_csv(f'50_clients_data/client_subG_splits/{name_state}.test', delimiter=',', names=list(self.features.keys()), skiprows=1, engine='python')\n",
    "\n",
    "        train_data = self.train_data_df.to_numpy()\n",
    "        test_data = self.test_data_df.to_numpy()\n",
    "\n",
    "        train_rows_to_keep = [not ('?' in row) for row in train_data]\n",
    "        test_rows_to_keep = [not ('?' in row) for row in test_data]\n",
    "\n",
    "        train_data = train_data[train_rows_to_keep]\n",
    "        test_data = test_data[test_rows_to_keep]\n",
    "\n",
    "        # remove the annoying dot from the test labels\n",
    "        for row in test_data:\n",
    "            # print(len(row))\n",
    "            # print(row[-1])\n",
    "\n",
    "            row[-1] = row[-1][:-1]\n",
    "\n",
    "        # convert to numeric features\n",
    "        train_data_num = to_numeric(train_data, self.features, label=self.label, single_bit_binary=self.single_bit_binary)\n",
    "        test_data_num = to_numeric(test_data, self.features, label=self.label, single_bit_binary=self.single_bit_binary)\n",
    "\n",
    "        # split features and labels\n",
    "        Xtrain, Xtest = train_data_num[:, :-1].astype(np.float32), test_data_num[:, :-1].astype(np.float32)\n",
    "        ytrain, ytest = train_data_num[:, -1].astype(np.float32), test_data_num[:, -1].astype(np.float32)\n",
    "\n",
    "        print(name_state,len(Xtrain))\n",
    "        print(\"ytrain\",np.unique(ytrain))\n",
    "        print(\"ytest\",np.unique(ytest))\n",
    "        \n",
    "        self.num_features = Xtrain.shape[1]\n",
    "\n",
    "        # transfer to torch\n",
    "        self.Xtrain, self.Xtest = torch.tensor(Xtrain).to(self.device), torch.tensor(Xtest).to(self.device)\n",
    "        self.ytrain, self.ytest = torch.tensor(ytrain, dtype=torch.long).to(self.device), torch.tensor(ytest, dtype=torch.long).to(self.device)\n",
    "\n",
    "        # set to train mode as base\n",
    "        self.train()\n",
    "\n",
    "        # calculate the standardization statistics\n",
    "        self._calculate_mean_std()\n",
    "\n",
    "        # calculate the histograms and feature bounds\n",
    "        self._calculate_categorical_feature_distributions_and_continuous_bounds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaad1865-8322-415e-bda3-82304b7ca884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_codes = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\",\n",
    "#                \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\",\n",
    "#                \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\",\n",
    "#                \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\",\n",
    "#                \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "\n",
    "# state_codes=[\"AK\"]\n",
    "# state_codes=[\"BM\",\"BW\",\"WM\",\"WW\"]\n",
    "state_codes=[\"male\",\"female\",\"white\",\"black\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614997b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae35a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc6f1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "278da44e",
   "metadata": {},
   "source": [
    "# pytorch 2.3 Loader -- SubGroup Processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3477ce61-d42c-407e-940f-05c0807a624a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male\n",
      "male 10000\n",
      "ytrain [0. 1.]\n",
      "ytest [0. 1.]\n",
      "female\n",
      "female 10000\n",
      "ytrain [0. 1.]\n",
      "ytest [0. 1.]\n",
      "white\n",
      "white 10000\n",
      "ytrain [0. 1.]\n",
      "ytest [0. 1.]\n",
      "black\n",
      "black 1000\n",
      "ytrain [0. 1.]\n",
      "ytest [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "for state_code in state_codes:\n",
    "    state_name=state_code\n",
    "    adult_dataset = ADULT(name_state=state_name)\n",
    "    adult_dataset.standardize()\n",
    "    dataset = TensorDataset(adult_dataset.Xtrain, adult_dataset.ytrain)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)  \n",
    "\n",
    "    with open(f'50_clients_data/client_subG_processed/{state_name}.pkl', 'wb') as f:\n",
    "        pickle.dump(dataloader, f)\n",
    "        \n",
    "    dataset = TensorDataset(adult_dataset.Xtest, adult_dataset.ytest)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)  \n",
    "    \n",
    "    with open(f'50_clients_data/client_subG_processed/{state_name}_test.pkl', 'wb') as f:\n",
    "        pickle.dump(dataloader, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e746fecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10016"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_name=\"male\"\n",
    "\n",
    "client_data_dir=\"50_clients_data/client_subG_processed/\"\n",
    "\n",
    "with open(client_data_dir+f'{state_name}.pkl', 'rb') as f:\n",
    "    train_data_all_client  = pickle.load(f)\n",
    "\n",
    "len(train_data_all_client)*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85a7760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adult_dataset.standardize()\n",
    "# adult_dataset.Xtest\n",
    "\n",
    "# # SEX, RAC1P are same... thats why its 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b399a15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adult_dataset.Xtest[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95a2aa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adult_dataset.de_standardize()\n",
    "# adult_dataset.Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73b6b814-f7b4-440b-a201-19fcd3279ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for state_code in state_codes:\n",
    "#     state_name=state_code\n",
    "#     adult_dataset = ADULT(name_state=state_name)\n",
    "#     adult_dataset.standardize()\n",
    "#     dataset = TensorDataset(adult_dataset.Xtrain, adult_dataset.ytrain)\n",
    "#     dataloader = DataLoader(dataset, batch_size=32, shuffle=True)  \n",
    "\n",
    "#     with open(f'50_clients_data/processed_data/{state_name}.pkl', 'wb') as f:\n",
    "#         pickle.dump(dataloader, f)\n",
    "        \n",
    "#     dataset = TensorDataset(adult_dataset.Xtest, adult_dataset.ytest)\n",
    "#     dataloader = DataLoader(dataset, batch_size=32, shuffle=True)  \n",
    "    \n",
    "#     with open(f'50_clients_data/processed_data/{state_name}_test.pkl', 'wb') as f:\n",
    "#         pickle.dump(dataloader, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3ef5cb-74a0-4033-a2fc-3172210a75e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dc00f21-4b92-4079-bdbb-40274a50b82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_name=\"WM\"\n",
    "\n",
    "client_data_dir=\"50_clients_data/client_subG_processed/\"\n",
    "\n",
    "with open(client_data_dir+f'{state_name}.pkl', 'rb') as f:\n",
    "    train_data_all_client  = pickle.load(f)\n",
    "\n",
    "len(train_data_all_client)*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7eddfd-e8a9-4e03-a822-b198284c537d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "430fbbf3-4112-4b0f-9723-d6471e6251e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_name=state_code\n",
    "# adult_dataset = ADULT(name_state=state_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c8ae69e-fc5b-4b41-adfd-49c9f8d6b1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adult_dataset.standardize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce26346e-4df0-4b96-bef1-f3e2883f7fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adult_dataset.Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60ba364-92a2-443f-947b-db96d3fba52e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b37538d-b8ef-48fa-9d01-cce848dde54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = TensorDataset(adult_dataset.Xtrain, adult_dataset.ytrain)\n",
    "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True)  \n",
    "\n",
    "# with open(f'50_clients_data/processed_data/{sta_name}.pkl', 'wb') as f:\n",
    "#     pickle.dump(dataloader, f)\n",
    "\n",
    "\n",
    "# dataset = TensorDataset(adult_dataset.Xtest, adult_dataset.ytest)\n",
    "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True)  \n",
    "\n",
    "# with open(f'50_clients_data/processed_data/{sta_name}_test.pkl', 'wb') as f:\n",
    "#     pickle.dump(dataloader, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47b022b-9976-4d40-9760-41d7b59c8826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0afaa707-b7c5-43db-9ca6-bfbfa772ae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('50_clients_data/processed_data/AL.pkl', 'rb') as f:\n",
    "    dfs_loaded = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b0a962-a7ff-47ec-9c6b-bfa51d6eb27a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d223db8-45dc-473e-a9c8-25466aa142ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a93aad86-252d-4a8c-a4f6-661ca48862e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for state_code, (features, label) in dfs.items():\n",
    "#     # take 30%\n",
    "#     num_rows_to_keep = int(len(features) * 0.3) \n",
    "#     random_indices = np.random.choice(len(features), num_rows_to_keep, replace=False)\n",
    "#     reduced_features = features.iloc[random_indices]\n",
    "#     reduced_label = label.iloc[random_indices]\n",
    "#     dfs[state_code] = (reduced_features, reduced_label)\n",
    "\n",
    "# for state_code, (reduced_features, reduced_label) in dfs.items():\n",
    "#     print(f\"State: {state_code}, Reduced Features Length: {len(reduced_features)}, Reduced Label Length: {len(reduced_label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a55148d4-3246-4808-ad56-98a288027ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Save the dictionary to a file\n",
    "# with open('dfs.pickle', 'wb') as f:\n",
    "#     pickle.dump(merge_dfs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c36daf13-b0c9-443d-893f-48b468e56723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('dfs.pickle', 'rb') as f:\n",
    "#     dfs_loaded = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "869ef307-92e7-481b-98a0-bb2f0f8e4a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for state_code, df in dfs_loaded.items():\n",
    "#     print(f\"State: {state_code}, df Length: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7a2d099-4666-42e0-8243-db5888c33c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs_loaded[\"TX\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067e7e84-6d73-4379-abdb-89054d2141a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
